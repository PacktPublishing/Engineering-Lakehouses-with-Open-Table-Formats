{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cca75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyiceberg[s3fs,sql-sqlite]\n",
      "  Downloading pyiceberg-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting requests<3.0.0,>=2.20.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting strictyaml<2.0.0,>=1.7.0\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.2.3\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting pydantic!=2.4.0,!=2.4.1,<3.0,>=2.0\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mmh3<5.0.0,>=4.0.0\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing<4.0.0,>=3.1.0\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec<2025.1.0,>=2023.1.0\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich<14.0.0,>=10.11.0\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sortedcontainers==2.4.0\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting s3fs<2024.1.0,>=2023.1.0\n",
      "  Downloading s3fs-2023.12.2-py3-none-any.whl (28 kB)\n",
      "Collecting sqlalchemy<3.0.0,>=2.0.18\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting pydantic-core==2.23.4\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /home/docker/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.20.0->pyiceberg[s3fs,sql-sqlite]) (3.4)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/docker/.local/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->pyiceberg[s3fs,sql-sqlite]) (2.13.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec<2025.1.0,>=2023.1.0\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiobotocore<3.0.0,>=2.5.4\n",
      "  Downloading aiobotocore-2.15.2-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.0 in /home/docker/.local/lib/python3.10/site-packages (from strictyaml<2.0.0,>=1.7.0->pyiceberg[s3fs,sql-sqlite]) (2.8.2)\n",
      "Collecting wrapt<2.0.0,>=1.10.10\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aioitertools<1.0.0,>=0.5.1\n",
      "  Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.35.37,>=1.35.16\n",
      "  Downloading botocore-1.35.36-py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/docker/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024.1.0,>=2023.1.0->pyiceberg[s3fs,sql-sqlite]) (22.1.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 KB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 KB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/docker/.local/lib/python3.10/site-packages (from python-dateutil>=2.6.0->strictyaml<2.0.0,>=1.7.0->pyiceberg[s3fs,sql-sqlite]) (1.16.0)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: sortedcontainers, mmh3, wrapt, urllib3, typing-extensions, tenacity, pyparsing, propcache, mdurl, jmespath, greenlet, fsspec, frozenlist, click, charset-normalizer, certifi, async-timeout, annotated-types, aioitertools, aiohappyeyeballs, strictyaml, sqlalchemy, requests, pydantic-core, multidict, markdown-it-py, botocore, aiosignal, yarl, rich, pydantic, pyiceberg, aiohttp, aiobotocore, s3fs\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/home/docker/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script markdown-it is installed in '/home/docker/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pyiceberg is installed in '/home/docker/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed aiobotocore-2.15.2 aiohappyeyeballs-2.4.3 aiohttp-3.11.2 aioitertools-0.12.0 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-5.0.1 botocore-1.35.36 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 frozenlist-1.5.0 fsspec-2023.12.2 greenlet-3.1.1 jmespath-1.0.1 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 multidict-6.1.0 propcache-0.2.0 pydantic-2.9.2 pydantic-core-2.23.4 pyiceberg-0.7.1 pyparsing-3.2.0 requests-2.32.3 rich-13.9.4 s3fs-2023.12.2 sortedcontainers-2.4.0 sqlalchemy-2.0.36 strictyaml-1.7.3 tenacity-8.5.0 typing-extensions-4.12.2 urllib3-2.2.3 wrapt-1.16.0 yarl-1.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"pyiceberg[s3fs,sql-sqlite]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56591cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340a30e",
   "metadata": {},
   "source": [
    "# Configure the SQLCatalog (Using a SQLLite Catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "\n",
    "# Define the warehouse path\n",
    "warehouse_path = \"/tmp/warehouse\"\n",
    "\n",
    "# Create the warehouse directory if it doesn't exist\n",
    "os.makedirs(warehouse_path, exist_ok=True)\n",
    "\n",
    "# Initialize the SqlCatalog with the warehouse path\n",
    "catalog = SqlCatalog(\n",
    "    \"default\",\n",
    "    **{\n",
    "        \"uri\": f\"sqlite:///{warehouse_path}/pyiceberg_catalog.db\",\n",
    "        \"warehouse\": f\"file://{warehouse_path}\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cab859",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5bad854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 45.4M  100 45.4M    0     0  28.9M      0  0:00:01  0:00:01 --:--:-- 28.9M\n"
     ]
    }
   ],
   "source": [
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet -o /tmp/yellow_tripdata_2023-01.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a537dc5",
   "metadata": {},
   "source": [
    "# Load data in a PyArrow DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "629860f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-18.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514d7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "df = pq.read_table(\"/tmp/yellow_tripdata_2023-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f92fd2d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID: int64\n",
       "tpep_pickup_datetime: timestamp[us]\n",
       "tpep_dropoff_datetime: timestamp[us]\n",
       "passenger_count: double\n",
       "trip_distance: double\n",
       "RatecodeID: double\n",
       "store_and_fwd_flag: string\n",
       "PULocationID: int64\n",
       "DOLocationID: int64\n",
       "payment_type: int64\n",
       "fare_amount: double\n",
       "extra: double\n",
       "mta_tax: double\n",
       "tip_amount: double\n",
       "tolls_amount: double\n",
       "improvement_surcharge: double\n",
       "total_amount: double\n",
       "congestion_surcharge: double\n",
       "airport_fee: double\n",
       "-- schema metadata --\n",
       "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 2492"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9dc2e3",
   "metadata": {},
   "source": [
    "# Define the Iceberg Table Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aaade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.schema import Schema, NestedField\n",
    "from pyiceberg.types import LongType, TimestampType, DoubleType, StringType\n",
    "\n",
    "# Define the Iceberg-compatible schema using NestedField with LongType for 64-bit integers\n",
    "iceberg_schema = Schema(\n",
    "    NestedField(id=1, name=\"VendorID\", field_type=LongType(), required=False),\n",
    "    NestedField(id=2, name=\"tpep_pickup_datetime\", field_type=TimestampType(), required=False),\n",
    "    NestedField(id=3, name=\"tpep_dropoff_datetime\", field_type=TimestampType(), required=False),\n",
    "    NestedField(id=4, name=\"passenger_count\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=5, name=\"trip_distance\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=6, name=\"RatecodeID\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=7, name=\"store_and_fwd_flag\", field_type=StringType(), required=False),\n",
    "    NestedField(id=8, name=\"PULocationID\", field_type=LongType(), required=False),\n",
    "    NestedField(id=9, name=\"DOLocationID\", field_type=LongType(), required=False),\n",
    "    NestedField(id=10, name=\"payment_type\", field_type=LongType(), required=False),\n",
    "    NestedField(id=11, name=\"fare_amount\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=12, name=\"extra\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=13, name=\"mta_tax\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=14, name=\"tip_amount\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=15, name=\"tolls_amount\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=16, name=\"improvement_surcharge\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=17, name=\"total_amount\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=18, name=\"congestion_surcharge\", field_type=DoubleType(), required=False),\n",
    "    NestedField(id=19, name=\"airport_fee\", field_type=DoubleType(), required=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85ef3d",
   "metadata": {},
   "source": [
    "# Now create the table with the specified schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179912de",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ice = catalog.create_table(\n",
    "    \"default.taxi_dataset_ice\",\n",
    "    schema=iceberg_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61b2e5",
   "metadata": {},
   "source": [
    "# Append data to the Iceberg table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44647ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ice.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e1fc3",
   "metadata": {},
   "source": [
    "# Read data from Iceberg Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c07cc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.expressions import GreaterThanOrEqual\n",
    "scan = ice_table.scan(\n",
    "    row_filter=GreaterThanOrEqual(\"trip_distance\", 10.0),\n",
    "    selected_fields=(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"),\n",
    "    limit=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3ea50",
   "metadata": {},
   "source": [
    "# Read data in Apache Arrow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eeb7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_record = scan.to_arrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b4cb1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "VendorID: int64\n",
       "tpep_pickup_datetime: timestamp[us]\n",
       "tpep_dropoff_datetime: timestamp[us]\n",
       "----\n",
       "VendorID: [[2,2,1,2,2,...,2,2,2,2,2]]\n",
       "tpep_pickup_datetime: [[2023-01-01 00:27:12.000000,2023-01-01 00:09:29.000000,2023-01-01 00:13:30.000000,2023-01-01 00:41:41.000000,2023-01-01 00:22:39.000000,...,2023-01-01 00:56:24.000000,2023-01-01 00:55:38.000000,2023-01-01 00:13:36.000000,2023-01-01 00:51:18.000000,2023-01-01 00:27:34.000000]]\n",
       "tpep_dropoff_datetime: [[2023-01-01 00:49:56.000000,2023-01-01 00:29:23.000000,2023-01-01 00:44:00.000000,2023-01-01 01:19:32.000000,2023-01-01 01:30:45.000000,...,2023-01-01 01:26:29.000000,2023-01-01 01:25:34.000000,2023-01-01 00:48:23.000000,2023-01-01 01:11:18.000000,2023-01-01 01:05:05.000000]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17dd86",
   "metadata": {},
   "source": [
    "# Read data in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "128af174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:27:12</td>\n",
       "      <td>2023-01-01 00:49:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:09:29</td>\n",
       "      <td>2023-01-01 00:29:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:13:30</td>\n",
       "      <td>2023-01-01 00:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:41:41</td>\n",
       "      <td>2023-01-01 01:19:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:22:39</td>\n",
       "      <td>2023-01-01 01:30:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:56:24</td>\n",
       "      <td>2023-01-01 01:26:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:38</td>\n",
       "      <td>2023-01-01 01:25:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:13:36</td>\n",
       "      <td>2023-01-01 00:48:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:51:18</td>\n",
       "      <td>2023-01-01 01:11:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:27:34</td>\n",
       "      <td>2023-01-01 01:05:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    VendorID tpep_pickup_datetime tpep_dropoff_datetime\n",
       "0          2  2023-01-01 00:27:12   2023-01-01 00:49:56\n",
       "1          2  2023-01-01 00:09:29   2023-01-01 00:29:23\n",
       "2          1  2023-01-01 00:13:30   2023-01-01 00:44:00\n",
       "3          2  2023-01-01 00:41:41   2023-01-01 01:19:32\n",
       "4          2  2023-01-01 00:22:39   2023-01-01 01:30:45\n",
       "..       ...                  ...                   ...\n",
       "95         2  2023-01-01 00:56:24   2023-01-01 01:26:29\n",
       "96         2  2023-01-01 00:55:38   2023-01-01 01:25:34\n",
       "97         2  2023-01-01 00:13:36   2023-01-01 00:48:23\n",
       "98         2  2023-01-01 00:51:18   2023-01-01 01:11:18\n",
       "99         2  2023-01-01 00:27:34   2023-01-01 01:05:05\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_record_pandas = scan.to_pandas()\n",
    "sc_record_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae848b96",
   "metadata": {},
   "source": [
    "# Load Iceberg Tables from an already configured Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582e7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "catalog_dev = load_catalog(\"docs\", **{\"uri\": f\"sqlite:///{warehouse_path}/pyiceberg_catalog.db\"})\n",
    "cust_table = catalog_dev.load_table(\"default.customers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
